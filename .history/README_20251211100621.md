# ‚≠ê Agent Workflow Engine (FastAPI)
A clean, beginner‚Äëfriendly workflow engine built as part of the **AI Engineering Internship Backend Assignment**.  
This project focuses on clarity, structure, and demonstrating strong backend fundamentals ‚Äî exactly what the assignment expects.

The engine behaves like a tiny, simplified version of **LangGraph**, allowing you to define steps (nodes), connect them, and execute workflows with a shared state.

No frontend.  
No machine learning.  
Just pure backend logic and clean system design. üöÄ

---

# 1Ô∏è‚É£ What This Project Is About

The internship assignment requires building a workflow engine that:

- Runs a sequence of steps (nodes)
- Maintains shared state between nodes
- Supports branching and looping
- Uses a tool registry (Python functions)  
- Exposes FastAPI endpoints to run the workflow

This project implements **Option B: Summarization + Refinement**, one of the sample workflows suggested.

---

# 2Ô∏è‚É£ What This Engine Can Do

### ‚úî Workflow Execution  
Nodes = Python functions that read & modify shared state.

Supports:
- Sequential execution  
- Conditional branching  
- Looping until a condition is satisfied  
- Step‚Äëby‚Äëstep run logs  

### ‚úî Tool Registry  
All workflow actions are stored like this:

```python
tools = {
    "split_text": split_text,
    "generate_summaries": generate_summaries,
    "merge_summaries": merge_summaries,
    "refine_summary": refine_summary
}
```

Nodes reference tools by **name**, making the system extremely easy to extend.

### ‚úî FastAPI Endpoints  
| Endpoint | Purpose |
|---------|----------|
| `POST /graph/create` | Create a graph workflow |
| `POST /graph/run` | Run the workflow |
| `GET /graph/state/{run_id}` | Fetch workflow run progress |
| `GET /graph/example` | Get pre-built summarization workflow |

Everything is stored in memory ‚Üí super lightweight and fast.

---

# 3Ô∏è‚É£ Implemented Workflow: Option B ‚Äî Summarization + Refinement

The sample workflow follows these steps:

### **Step 1 ‚Äî Split Text**
Break large text into chunks of `max_chunk_size`.

### **Step 2 ‚Äî Generate Summaries**
Truncate each chunk to create ‚Äúsummaries‚Äù.

### **Step 3 ‚Äî Merge Summaries**
Combine all summaries into a single long summary.

### **Step 4 ‚Äî Refine Summary**
Trim summary to meet `summary_char_limit`.

### **Stopping Condition**
Workflow loops until:

```
summary_length <= summary_char_limit
```

This demonstrates:
- Proper looping  
- Clean state management  
- Node transitions  
- Modular tool design  

---

# 4Ô∏è‚É£ Project Structure

```
app/
‚îÇ‚îÄ‚îÄ main.py        # FastAPI app & API routing
‚îÇ‚îÄ‚îÄ engine.py      # Core workflow execution engine
‚îÇ‚îÄ‚îÄ models.py      # Pydantic request/response models
‚îÇ‚îÄ‚îÄ store.py       # In-memory storage (graphs + runs)
‚îÇ‚îÄ‚îÄ tools.py       # Tools + Example workflow definition
README.md
```

---

# 5Ô∏è‚É£ How to Run This Project (VERY IMPORTANT)

This section is written with **extra clarity** so that anyone ‚Äî even someone new ‚Äî can run the workflow successfully.

---

## ‚úÖ Step 1: Create your virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
```

‚ö†Ô∏è *Make sure your terminal is inside the project folder before running this.*

---

## ‚úÖ Step 2: Install required packages
```bash
pip install fastapi uvicorn
```

These are the only dependencies needed.

---

## ‚úÖ Step 3: Start FastAPI Server
```bash
uvicorn app.main:app --reload
```

If this runs without errors, you‚Äôll see:
```
Uvicorn running on http://127.0.0.1:8000
```

---

## ‚úÖ Step 4: Open Swagger Docs  
Go to:

üëâ http://127.0.0.1:8000/docs

This is where you will **interact with the workflow engine**.

---

# 6Ô∏è‚É£ Running the Workflow (What YOU actually did!)

Here is exactly how the workflow can be tested ‚Äî the same steps you used while running it:

---

## üîπ Step A ‚Äî Fetch Example Workflow
```
GET /graph/example
```

This returns:
- Node definitions  
- Edges  
- Start node  
- A unique `graph_id`  

This `graph_id` is required for the next step.

---

## üîπ Step B ‚Äî Execute Workflow
Use:

```
POST /graph/run
```

Example Body:
```json
{
  "graph_id": "YOUR_GRAPH_ID",
  "initial_state": {
    "text": "Your long text...",
    "max_chunk_size": 100,
    "summary_char_limit": 120
  }
}
```

---

## üîπ Step C ‚Äî What You Receive as Output

You will get:

### ‚úÖ `final_state`  
Contains:
- chunks  
- summaries  
- merged summary  
- refined summary  
- final summary length  

### ‚úÖ `log`  
Every step executed with:
- node name  
- tool used  
- next node  
- state after each step  

### ‚úÖ `run_id`  
Useful for checking state again via:

```
GET /graph/state/{run_id}
```

This makes your workflow **fully observable**, which is exactly what the assignment expects.

---

# 7Ô∏è‚É£ How This Project Fulfills All Assignment Requirements

### ‚úî Minimal Workflow Engine  
Nodes, transitions, state mutation, branching, and looping implemented.

### ‚úî Tool Registry  
Easy-to-extend dictionary-based tool system.

### ‚úî FastAPI Endpoints  
Graph creation ‚Üí workflow execution ‚Üí state retrieval all functional.

### ‚úî Looping Logic  
Workflow continues until summary fits the required character limit.

### ‚úî Clear Code Structure  
Each file has a single responsibility ‚Äî clean and readable.

### ‚úî No ML / No Frontend  
Fully matches assignment constraints.

---

# üîü Final Notes

This project offers a clean and simple backend architecture that meets every requirement of the internship assignment.  
It is easy to understand, easy to extend, and fully demonstrates:

- Python async fundamentals  
- Workflow/state management  
- API design  
- Looping & branching logic  
- Logging and observability  

If more time was available, extensions could include:
- Persistent DB storage  
- WebSocket log streaming  
- Visual graph debugging  
- Real summarization logic  

---

üéâ Thank you for reviewing this project!  
If you want to add diagrams, explanations, or GIF-based demos to this README, just ask.  
