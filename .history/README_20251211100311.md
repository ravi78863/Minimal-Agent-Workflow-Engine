### 1. Retrieve the Example Workflow  
This project includes the **Summarization + Refinement workflow (Option B)** as a ready‑to‑run example.  
You can fetch its full graph definition using:

```
GET /graph/example
```

This returns:
- All nodes included in the workflow  
- The execution order (edges)  
- The start node  
- The stop condition  

---

### 2. Execute the Workflow  
Once you receive the `graph_id`, you can run the workflow by providing an initial state:

```json
{
  "graph_id": "YOUR_GRAPH_ID",
  "initial_state": {
    "text": "Your long text...",
    "max_chunk_size": 100,
    "summary_char_limit": 120
  }
}
```

During execution, your workflow will:
1. Split text into chunks  
2. Summarize each chunk  
3. Merge summaries  
4. Refine to the required character limit  
5. Automatically stop when the limit condition is satisfied  

---

### 3. Output You Receive  
After running the workflow, the API returns:

- **Final State:**  
  Contains final summary, chunks, intermediate summaries, final summary length, and any loop‑related updates.

- **Execution Log:**  
  A detailed record of each step executed, including:  
  - Which node ran  
  - What tool was invoked  
  - How the shared state changed  
  - Whether loops or conditions were triggered  

- **Run ID:**  
  Allows retrieving the workflow state later via:  
  ```
  GET /graph/state/{run_id}
  ```

---

## 7. How This Project Satisfies Assignment Requirements

### ✔ Minimal Workflow Engine  
This implementation fully covers the assignment criteria by supporting:  
- **State propagation:** Shared state dictionary updated at each node  
- **Node-based execution:** Every step is a tool function operating on state  
- **Transitions:** Edges determine next node  
- **Branching:** Refinement step checks character limit and routes accordingly  
- **Looping:** The engine repeatedly executes the merge → refine cycle until summary meets the limit  
- **Logging:** Every step is recorded for transparency  
